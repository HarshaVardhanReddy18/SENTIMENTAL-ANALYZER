{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/H/Downloads/DATA (3).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>[ On days when I feel close to my partner and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                              Words\n",
       "0      joy  [ On days when I feel close to my partner and ...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\H\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\H\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\H\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\H\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7682"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "index = []\n",
    "for word in df['Words']:\n",
    "    if word == '[ No response.]':\n",
    "        index.append(c)\n",
    "        c+=1\n",
    "    else:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>[on, days, when, i, feel, close, to, my, partn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>[every, time, i, imagine, that, someone, i, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>[when, i, had, been, obviously, unjustly, trea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>[when, i, think, about, the, short, time, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>[at, a, gathering, i, found, myself, involunta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                              Words\n",
       "0      joy  [on, days, when, i, feel, close, to, my, partn...\n",
       "1     fear  [every, time, i, imagine, that, someone, i, lo...\n",
       "2    anger  [when, i, had, been, obviously, unjustly, trea...\n",
       "3  sadness  [when, i, think, about, the, short, time, that...\n",
       "4  disgust  [at, a, gathering, i, found, myself, involunta..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df['Words'])):\n",
    "    df['Words'][i] = df['Words'][i].lower()\n",
    "    df['Words'][i] = df['Words'][i].translate(str.maketrans('','',string.punctuation))\n",
    "    df['Words'][i] = df['Words'][i].translate(str.maketrans('','','รฃยก'))\n",
    "    df['Words'][i] = df['Words'][i].translate(str.maketrans('','','\\r\\n'))\n",
    "    df['Words'][i] = word_tokenize(df['Words'][i],'english')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Words</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>[on, days, when, i, feel, close, to, my, partn...</td>\n",
       "      <td>[days, feel, close, partner, friends, feel, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>[every, time, i, imagine, that, someone, i, lo...</td>\n",
       "      <td>[every, time, imagine, someone, love, could, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>[when, i, had, been, obviously, unjustly, trea...</td>\n",
       "      <td>[obviously, unjustly, treated, possibility, el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>[when, i, think, about, the, short, time, that...</td>\n",
       "      <td>[think, short, time, live, relate, periods, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>[at, a, gathering, i, found, myself, involunta...</td>\n",
       "      <td>[gathering, found, involuntarily, sitting, nex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                              Words  \\\n",
       "0      joy  [on, days, when, i, feel, close, to, my, partn...   \n",
       "1     fear  [every, time, i, imagine, that, someone, i, lo...   \n",
       "2    anger  [when, i, had, been, obviously, unjustly, trea...   \n",
       "3  sadness  [when, i, think, about, the, short, time, that...   \n",
       "4  disgust  [at, a, gathering, i, found, myself, involunta...   \n",
       "\n",
       "                                               words  \n",
       "0  [days, feel, close, partner, friends, feel, pe...  \n",
       "1  [every, time, imagine, someone, love, could, c...  \n",
       "2  [obviously, unjustly, treated, possibility, el...  \n",
       "3  [think, short, time, live, relate, periods, li...  \n",
       "4  [gathering, found, involuntarily, sitting, nex...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words'] = df['Words']\n",
    "for i in range(len(df['Words'])):\n",
    "    df['words'][i] = []\n",
    "    for word in df['Words'][i]:\n",
    "        if word not in stop:\n",
    "            df['words'][i].append(word)\n",
    "            \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem'] = df['words']\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(df['words'])):\n",
    "    df['lem'][i] = []\n",
    "    for word in df['words'][i]:\n",
    "        df['lem'][i].append(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Words</th>\n",
       "      <th>words</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>[on, days, when, i, feel, close, to, my, partn...</td>\n",
       "      <td>[days, feel, close, partner, friends, feel, pe...</td>\n",
       "      <td>[day, feel, close, partner, friend, feel, peac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>[every, time, i, imagine, that, someone, i, lo...</td>\n",
       "      <td>[every, time, imagine, someone, love, could, c...</td>\n",
       "      <td>[every, time, imagine, someone, love, could, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>[when, i, had, been, obviously, unjustly, trea...</td>\n",
       "      <td>[obviously, unjustly, treated, possibility, el...</td>\n",
       "      <td>[obviously, unjustly, treated, possibility, el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>[when, i, think, about, the, short, time, that...</td>\n",
       "      <td>[think, short, time, live, relate, periods, li...</td>\n",
       "      <td>[think, short, time, live, relate, period, lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>[at, a, gathering, i, found, myself, involunta...</td>\n",
       "      <td>[gathering, found, involuntarily, sitting, nex...</td>\n",
       "      <td>[gathering, found, involuntarily, sitting, nex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                              Words  \\\n",
       "0      joy  [on, days, when, i, feel, close, to, my, partn...   \n",
       "1     fear  [every, time, i, imagine, that, someone, i, lo...   \n",
       "2    anger  [when, i, had, been, obviously, unjustly, trea...   \n",
       "3  sadness  [when, i, think, about, the, short, time, that...   \n",
       "4  disgust  [at, a, gathering, i, found, myself, involunta...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [days, feel, close, partner, friends, feel, pe...   \n",
       "1  [every, time, imagine, someone, love, could, c...   \n",
       "2  [obviously, unjustly, treated, possibility, el...   \n",
       "3  [think, short, time, live, relate, periods, li...   \n",
       "4  [gathering, found, involuntarily, sitting, nex...   \n",
       "\n",
       "                                                 lem  \n",
       "0  [day, feel, close, partner, friend, feel, peac...  \n",
       "1  [every, time, imagine, someone, love, could, c...  \n",
       "2  [obviously, unjustly, treated, possibility, el...  \n",
       "3  [think, short, time, live, relate, period, lif...  \n",
       "4  [gathering, found, involuntarily, sitting, nex...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7605 entries, 0 to 7681\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Emotion  7605 non-null   object\n",
      " 1   Words    7605 non-null   object\n",
      " 2   words    7605 non-null   object\n",
      " 3   lem      7605 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 297.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(index)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"C:/Users/H/Documents/english words.txt\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = []\n",
    "for word in f:\n",
    "    corp.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58110"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corp)):\n",
    "    corp[i] = str(corp[i]).translate(str.maketrans('','','\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem'] = [' '.join(x) for x in df['lem'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Words</th>\n",
       "      <th>words</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>[on, days, when, i, feel, close, to, my, partn...</td>\n",
       "      <td>[days, feel, close, partner, friends, feel, pe...</td>\n",
       "      <td>day feel close partner friend feel peace also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>[every, time, i, imagine, that, someone, i, lo...</td>\n",
       "      <td>[every, time, imagine, someone, love, could, c...</td>\n",
       "      <td>every time imagine someone love could contact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>[when, i, had, been, obviously, unjustly, trea...</td>\n",
       "      <td>[obviously, unjustly, treated, possibility, el...</td>\n",
       "      <td>obviously unjustly treated possibility elucida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>[when, i, think, about, the, short, time, that...</td>\n",
       "      <td>[think, short, time, live, relate, periods, li...</td>\n",
       "      <td>think short time live relate period life think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>[at, a, gathering, i, found, myself, involunta...</td>\n",
       "      <td>[gathering, found, involuntarily, sitting, nex...</td>\n",
       "      <td>gathering found involuntarily sitting next two...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                              Words  \\\n",
       "0      joy  [on, days, when, i, feel, close, to, my, partn...   \n",
       "1     fear  [every, time, i, imagine, that, someone, i, lo...   \n",
       "2    anger  [when, i, had, been, obviously, unjustly, trea...   \n",
       "3  sadness  [when, i, think, about, the, short, time, that...   \n",
       "4  disgust  [at, a, gathering, i, found, myself, involunta...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [days, feel, close, partner, friends, feel, pe...   \n",
       "1  [every, time, imagine, someone, love, could, c...   \n",
       "2  [obviously, unjustly, treated, possibility, el...   \n",
       "3  [think, short, time, live, relate, periods, li...   \n",
       "4  [gathering, found, involuntarily, sitting, nex...   \n",
       "\n",
       "                                                 lem  \n",
       "0  day feel close partner friend feel peace also ...  \n",
       "1  every time imagine someone love could contact ...  \n",
       "2  obviously unjustly treated possibility elucida...  \n",
       "3  think short time live relate period life think...  \n",
       "4  gathering found involuntarily sitting next two...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df['lem'],df['Emotion'],stratify = df['Emotion'],test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corp)\n",
    "max_length = max([len(x.split()) for x in df['lem']])\n",
    "v_size = len(tokenizer.word_index)+1\n",
    "\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_padding = pad_sequences(x_train_tokens,maxlen=max_length,padding = 'post')\n",
    "x_test_padding = pad_sequences(x_test_tokens,maxlen=max_length,padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Softmax, Flatten, Conv1D, GlobalMaxPooling1D, LeakyReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "dim = 200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(v_size,dim,input_length = max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(7,activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_padding,y_train,batch_size = 129, epochs = 10, validation_data = (x_test_padding,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5703 samples, validate on 1902 samples\n",
      "Epoch 1/10\n",
      "5703/5703 [==============================] - 15s 3ms/step - loss: 1.9256 - acc: 0.1832 - val_loss: 1.8249 - val_acc: 0.2992\n",
      "Epoch 2/10\n",
      "5703/5703 [==============================] - 15s 3ms/step - loss: 1.4593 - acc: 0.4578 - val_loss: 1.3529 - val_acc: 0.5252\n",
      "Epoch 3/10\n",
      "5703/5703 [==============================] - 15s 3ms/step - loss: 0.8063 - acc: 0.7231 - val_loss: 1.3974 - val_acc: 0.5421\n",
      "Epoch 4/10\n",
      "5703/5703 [==============================] - 16s 3ms/step - loss: 0.4171 - acc: 0.8702 - val_loss: 1.7402 - val_acc: 0.5421\n",
      "Epoch 5/10\n",
      "5703/5703 [==============================] - 15s 3ms/step - loss: 0.2267 - acc: 0.9304 - val_loss: 2.0865 - val_acc: 0.5252\n",
      "Epoch 6/10\n",
      "5703/5703 [==============================] - 15s 3ms/step - loss: 0.1409 - acc: 0.9593 - val_loss: 2.4264 - val_acc: 0.5336\n",
      "Epoch 7/10\n",
      "5703/5703 [==============================] - 15s 3ms/step - loss: 0.0920 - acc: 0.9714 - val_loss: 2.7282 - val_acc: 0.5179\n",
      "Epoch 8/10\n",
      "5703/5703 [==============================] - 16s 3ms/step - loss: 0.0657 - acc: 0.9807 - val_loss: 2.9742 - val_acc: 0.5216\n",
      "Epoch 9/10\n",
      "5703/5703 [==============================] - 16s 3ms/step - loss: 0.0496 - acc: 0.9851 - val_loss: 3.2631 - val_acc: 0.5195\n",
      "Epoch 10/10\n",
      "5703/5703 [==============================] - 17s 3ms/step - loss: 0.0416 - acc: 0.9868 - val_loss: 3.4827 - val_acc: 0.5184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23f33219e88>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Softmax, Flatten, Conv1D, GlobalMaxPooling1D, LeakyReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "dim=200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(v_size,dim,input_length = max_length))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(Conv1D(256, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.fit(x_train_padding,y_train, batch_size = 128, epochs = 10, validation_data = (x_test_padding, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 100\n",
    "from keras.layers import Dense, GRU, Softmax, Flatten, Conv1D, GlobalMaxPooling1D, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(v_size,dim,input_length = max_length))\n",
    "model.add(LSTM(200,return_sequences = True))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dense(7,activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_padding,y_train, batch_size = 128, epochs = 10, validation_data = (x_test_padding, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxtrain,mxtest,mytrain,mytest = train_test_split(df['lem'],df['Emotion'],stratify = df['Emotion'],test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "vect = TfidfVectorizer(analyzer = 'word',ngram_range=(1, 3),stop_words = 'english')\n",
    "vect = vect.fit(df['lem'])\n",
    "\n",
    "mxtrain1 = vect.transform(mxtrain)\n",
    "mxtest1 = vect.transform(mxtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbenc = LabelEncoder()\n",
    "mytrain = lbenc.fit_transform(mytrain)\n",
    "mytest = lbenc.transform(mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544689800210305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=150).fit(mxtrain1,mytrain)\n",
    "predictions = model.predict(mxtest1)\n",
    "print(accuracy_score(mytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5694006309148265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = MultinomialNB(alpha = 1).fit(mxtrain1,mytrain)\n",
    "predictions = model.predict(mxtest1)\n",
    "print(accuracy_score(mytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbenc.inverse_transform(model.predict(vect.transform([\"How are you\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actually bad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = []\n",
    "text = 'Actually this is very bad '\n",
    "text = text.lower()\n",
    "text = text.translate(str.maketrans('','',string.punctuation))\n",
    "text = word_tokenize(text)\n",
    "for word in text:\n",
    "    if word not in stop:\n",
    "        best.append(word)\n",
    "for i in range(len(best)):\n",
    "    best[i] = lemmatizer.lemmatize(best[i])\n",
    "a = ' '.join([str(elem) for elem in best]) \n",
    "print(a)\n",
    "lbenc.inverse_transform(model.predict(vect.transform([a])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
